{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d118501b-7c77-4c46-b47b-b890729370d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datacenter: datacenter1\n",
      "=======================\n",
      "Status=Up/Down\n",
      "|/ State=Normal/Leaving/Joining/Moving\n",
      "--  Address       Load        Tokens  Owns (effective)  Host ID                               Rack \n",
      "UN  192.168.16.2  104.34 KiB  16      65.5%             e48f360c-7ad1-4808-94a0-5d0b15eda902  rack1\n",
      "UN  192.168.16.3  104.36 KiB  16      74.6%             44ad5ccc-41e2-41b0-b7db-b5f42de37cc2  rack1\n",
      "UN  192.168.16.4  104.34 KiB  16      59.9%             bfa98803-80c5-4988-97b2-2b7d367f50bb  rack1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check node state\n",
    "! nodetool status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d53fb21-d98a-4747-b469-52860b0d24da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f00d891ceb0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create keyspace(database) and import data\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster(['p6-db-1', 'p6-db-2', 'p6-db-3'])\n",
    "cass = cluster.connect()\n",
    "cass.execute('drop keyspace if exists weather')\n",
    "cass.execute(\"create keyspace weather with replication={'class': 'SimpleStrategy', 'replication_factor': 3}\")\n",
    "cass.execute('use weather')\n",
    "cass.execute('''\n",
    "create type station_record(\n",
    "    tmin INT,\n",
    "    tmax INT\n",
    ")\n",
    "''')\n",
    "cass.execute('''\n",
    "create table stations(\n",
    "    id TEXT,\n",
    "    name TEXT STATIC,\n",
    "    date DATE,\n",
    "    record weather.station_record,\n",
    "    PRIMARY KEY((id), date)\n",
    ") WITH CLUSTERING ORDER BY (date ASC)\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0ab5f97-1056-4163-8e40-7df2e0ee1fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"CREATE TABLE weather.stations (\\n    id text,\\n    date date,\\n    name text static,\\n    record station_record,\\n    PRIMARY KEY (id, date)\\n) WITH CLUSTERING ORDER BY (date ASC)\\n    AND additional_write_policy = '99p'\\n    AND bloom_filter_fp_chance = 0.01\\n    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}\\n    AND cdc = false\\n    AND comment = ''\\n    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}\\n    AND compression = {'chunk_length_in_kb': '16', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}\\n    AND memtable = 'default'\\n    AND crc_check_chance = 1.0\\n    AND default_time_to_live = 0\\n    AND extensions = {}\\n    AND gc_grace_seconds = 864000\\n    AND max_index_interval = 2048\\n    AND memtable_flush_period_in_ms = 0\\n    AND min_index_interval = 128\\n    AND read_repair = 'BLOCKING'\\n    AND speculative_retry = '99p';\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q1\n",
    "cass.execute('describe table weather.stations').one().create_statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e038914c-bab2-44f2-be0a-3eb4c147bde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.10/dist-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "com.datastax.spark#spark-cassandra-connector_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-f249c220-a88a-4e4b-907b-722dde85a628;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.datastax.spark#spark-cassandra-connector_2.12;3.4.0 in central\n",
      "\tfound com.datastax.spark#spark-cassandra-connector-driver_2.12;3.4.0 in central\n",
      "\tfound com.datastax.oss#java-driver-core-shaded;4.13.0 in central\n",
      "\tfound com.datastax.oss#native-protocol;1.5.0 in central\n",
      "\tfound com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 in central\n",
      "\tfound com.typesafe#config;1.4.1 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.26 in central\n",
      "\tfound io.dropwizard.metrics#metrics-core;4.1.18 in central\n",
      "\tfound org.hdrhistogram#HdrHistogram;2.1.12 in central\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.3 in central\n",
      "\tfound com.github.stephenc.jcip#jcip-annotations;1.0-1 in central\n",
      "\tfound com.github.spotbugs#spotbugs-annotations;3.1.12 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound com.datastax.oss#java-driver-mapper-runtime;4.13.0 in central\n",
      "\tfound com.datastax.oss#java-driver-query-builder;4.13.0 in central\n",
      "\tfound org.apache.commons#commons-lang3;3.10 in central\n",
      "\tfound com.thoughtworks.paranamer#paranamer;2.8 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.11 in central\n",
      "downloading https://repo1.maven.org/maven2/com/datastax/spark/spark-cassandra-connector_2.12/3.4.0/spark-cassandra-connector_2.12-3.4.0.jar ...\n",
      "\t[SUCCESSFUL ] com.datastax.spark#spark-cassandra-connector_2.12;3.4.0!spark-cassandra-connector_2.12.jar (120ms)\n",
      "downloading https://repo1.maven.org/maven2/com/datastax/spark/spark-cassandra-connector-driver_2.12/3.4.0/spark-cassandra-connector-driver_2.12-3.4.0.jar ...\n",
      "\t[SUCCESSFUL ] com.datastax.spark#spark-cassandra-connector-driver_2.12;3.4.0!spark-cassandra-connector-driver_2.12.jar (67ms)\n",
      "downloading https://repo1.maven.org/maven2/com/datastax/oss/java-driver-core-shaded/4.13.0/java-driver-core-shaded-4.13.0.jar ...\n",
      "\t[SUCCESSFUL ] com.datastax.oss#java-driver-core-shaded;4.13.0!java-driver-core-shaded.jar (274ms)\n",
      "downloading https://repo1.maven.org/maven2/com/datastax/oss/java-driver-mapper-runtime/4.13.0/java-driver-mapper-runtime-4.13.0.jar ...\n",
      "\t[SUCCESSFUL ] com.datastax.oss#java-driver-mapper-runtime;4.13.0!java-driver-mapper-runtime.jar(bundle) (31ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/commons/commons-lang3/3.10/commons-lang3-3.10.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.commons#commons-lang3;3.10!commons-lang3.jar (48ms)\n",
      "downloading https://repo1.maven.org/maven2/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar ...\n",
      "\t[SUCCESSFUL ] com.thoughtworks.paranamer#paranamer;2.8!paranamer.jar(bundle) (31ms)\n",
      "downloading https://repo1.maven.org/maven2/org/scala-lang/scala-reflect/2.12.11/scala-reflect-2.12.11.jar ...\n",
      "\t[SUCCESSFUL ] org.scala-lang#scala-reflect;2.12.11!scala-reflect.jar (133ms)\n",
      "downloading https://repo1.maven.org/maven2/com/datastax/oss/native-protocol/1.5.0/native-protocol-1.5.0.jar ...\n",
      "\t[SUCCESSFUL ] com.datastax.oss#native-protocol;1.5.0!native-protocol.jar(bundle) (41ms)\n",
      "downloading https://repo1.maven.org/maven2/com/datastax/oss/java-driver-shaded-guava/25.1-jre-graal-sub-1/java-driver-shaded-guava-25.1-jre-graal-sub-1.jar ...\n",
      "\t[SUCCESSFUL ] com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1!java-driver-shaded-guava.jar (120ms)\n",
      "downloading https://repo1.maven.org/maven2/com/typesafe/config/1.4.1/config-1.4.1.jar ...\n",
      "\t[SUCCESSFUL ] com.typesafe#config;1.4.1!config.jar(bundle) (67ms)\n",
      "downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.26/slf4j-api-1.7.26.jar ...\n",
      "\t[SUCCESSFUL ] org.slf4j#slf4j-api;1.7.26!slf4j-api.jar (30ms)\n",
      "downloading https://repo1.maven.org/maven2/io/dropwizard/metrics/metrics-core/4.1.18/metrics-core-4.1.18.jar ...\n",
      "\t[SUCCESSFUL ] io.dropwizard.metrics#metrics-core;4.1.18!metrics-core.jar(bundle) (29ms)\n",
      "downloading https://repo1.maven.org/maven2/org/hdrhistogram/HdrHistogram/2.1.12/HdrHistogram-2.1.12.jar ...\n",
      "\t[SUCCESSFUL ] org.hdrhistogram#HdrHistogram;2.1.12!HdrHistogram.jar(bundle) (31ms)\n",
      "downloading https://repo1.maven.org/maven2/org/reactivestreams/reactive-streams/1.0.3/reactive-streams-1.0.3.jar ...\n",
      "\t[SUCCESSFUL ] org.reactivestreams#reactive-streams;1.0.3!reactive-streams.jar (26ms)\n",
      "downloading https://repo1.maven.org/maven2/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar ...\n",
      "\t[SUCCESSFUL ] com.github.stephenc.jcip#jcip-annotations;1.0-1!jcip-annotations.jar (27ms)\n",
      "downloading https://repo1.maven.org/maven2/com/github/spotbugs/spotbugs-annotations/3.1.12/spotbugs-annotations-3.1.12.jar ...\n",
      "\t[SUCCESSFUL ] com.github.spotbugs#spotbugs-annotations;3.1.12!spotbugs-annotations.jar (26ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar ...\n",
      "\t[SUCCESSFUL ] com.google.code.findbugs#jsr305;3.0.2!jsr305.jar (25ms)\n",
      "downloading https://repo1.maven.org/maven2/com/datastax/oss/java-driver-query-builder/4.13.0/java-driver-query-builder-4.13.0.jar ...\n",
      "\t[SUCCESSFUL ] com.datastax.oss#java-driver-query-builder;4.13.0!java-driver-query-builder.jar(bundle) (33ms)\n",
      ":: resolution report :: resolve 5133ms :: artifacts dl 1195ms\n",
      "\t:: modules in use:\n",
      "\tcom.datastax.oss#java-driver-core-shaded;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-mapper-runtime;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-query-builder;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 from central in [default]\n",
      "\tcom.datastax.oss#native-protocol;1.5.0 from central in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector-driver_2.12;3.4.0 from central in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector_2.12;3.4.0 from central in [default]\n",
      "\tcom.github.spotbugs#spotbugs-annotations;3.1.12 from central in [default]\n",
      "\tcom.github.stephenc.jcip#jcip-annotations;1.0-1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.thoughtworks.paranamer#paranamer;2.8 from central in [default]\n",
      "\tcom.typesafe#config;1.4.1 from central in [default]\n",
      "\tio.dropwizard.metrics#metrics-core;4.1.18 from central in [default]\n",
      "\torg.apache.commons#commons-lang3;3.10 from central in [default]\n",
      "\torg.hdrhistogram#HdrHistogram;2.1.12 from central in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.3 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.11 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.26 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   18  |   18  |   18  |   0   ||   18  |   18  |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-f249c220-a88a-4e4b-907b-722dde85a628\n",
      "\tconfs: [default]\n",
      "\t18 artifacts copied, 0 already retrieved (18067kB/57ms)\n",
      "23/11/22 20:18:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# get \n",
    "from pyspark.sql import SparkSession\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"p6\")\n",
    "         .config('spark.jars.packages', 'com.datastax.spark:spark-cassandra-connector_2.12:3.4.0')\n",
    "         .config(\"spark.sql.extensions\", \"com.datastax.spark.connector.CassandraSparkExtensions\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "604afc63-6275-4293-bfa1-a5ae47dccc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, expr, lower\n",
    "df = spark.read.text('ghcnd-stations.txt')\n",
    "df = df.withColumn('ID', expr('substring (value,1,11)'))\n",
    "df = df.withColumn('STATE', expr('substring (value,39,2)'))\n",
    "df = df.withColumn('NAME', expr('substring (value,42,30)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f724c85-b695-4998-b29f-ee5fec7bc9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.select('state').limit(10).filter(lower(col('state')).like(\"%st johns%\")).toPandas()\n",
    "df = df.filter(lower(col('state')).like('%wi%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "056f1ef0-ae22-43cb-aa36-afbb226d21b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>ID</th>\n",
       "      <th>STATE</th>\n",
       "      <th>NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US1WIAD0002  43.9544  -89.8096  294.4 WI ADAMS...</td>\n",
       "      <td>US1WIAD0002</td>\n",
       "      <td>WI</td>\n",
       "      <td>ADAMS 0.4 E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US1WIAD0005  44.2053  -89.8480  305.7 WI NEKOO...</td>\n",
       "      <td>US1WIAD0005</td>\n",
       "      <td>WI</td>\n",
       "      <td>NEKOOSA 8.0 SSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US1WIAD0006  43.8858  -89.7259  307.8 WI GRAND...</td>\n",
       "      <td>US1WIAD0006</td>\n",
       "      <td>WI</td>\n",
       "      <td>GRAND MARSH 1.0 W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US1WIAD0008  43.8611  -89.7163  310.0 WI GRAND...</td>\n",
       "      <td>US1WIAD0008</td>\n",
       "      <td>WI</td>\n",
       "      <td>GRAND MARSH 1.9 SSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US1WIAD0010  43.7864  -89.6417  293.8 WI OXFOR...</td>\n",
       "      <td>US1WIAD0010</td>\n",
       "      <td>WI</td>\n",
       "      <td>OXFORD 4.0 W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>USW00094930  43.9333  -90.2667  280.1 WI VOLK ...</td>\n",
       "      <td>USW00094930</td>\n",
       "      <td>WI</td>\n",
       "      <td>VOLK FLD ANG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>USW00094940  43.9667  -90.7333  252.7 WI SPART...</td>\n",
       "      <td>USW00094940</td>\n",
       "      <td>WI</td>\n",
       "      <td>SPARTA FT MCCOY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>USW00094973  46.0303  -91.4425  368.8 WI HAYWA...</td>\n",
       "      <td>USW00094973</td>\n",
       "      <td>WI</td>\n",
       "      <td>HAYWARD MUNI AP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>USW00094985  44.6378  -90.1875  381.6 WI MARSH...</td>\n",
       "      <td>USW00094985</td>\n",
       "      <td>WI</td>\n",
       "      <td>MARSHFIELD MUNI AP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>USW00094994  43.1561  -90.6775  203.0 WI BOSCO...</td>\n",
       "      <td>USW00094994</td>\n",
       "      <td>WI</td>\n",
       "      <td>BOSCOBEL AP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1313 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  value           ID STATE  \\\n",
       "0     US1WIAD0002  43.9544  -89.8096  294.4 WI ADAMS...  US1WIAD0002    WI   \n",
       "1     US1WIAD0005  44.2053  -89.8480  305.7 WI NEKOO...  US1WIAD0005    WI   \n",
       "2     US1WIAD0006  43.8858  -89.7259  307.8 WI GRAND...  US1WIAD0006    WI   \n",
       "3     US1WIAD0008  43.8611  -89.7163  310.0 WI GRAND...  US1WIAD0008    WI   \n",
       "4     US1WIAD0010  43.7864  -89.6417  293.8 WI OXFOR...  US1WIAD0010    WI   \n",
       "...                                                 ...          ...   ...   \n",
       "1308  USW00094930  43.9333  -90.2667  280.1 WI VOLK ...  USW00094930    WI   \n",
       "1309  USW00094940  43.9667  -90.7333  252.7 WI SPART...  USW00094940    WI   \n",
       "1310  USW00094973  46.0303  -91.4425  368.8 WI HAYWA...  USW00094973    WI   \n",
       "1311  USW00094985  44.6378  -90.1875  381.6 WI MARSH...  USW00094985    WI   \n",
       "1312  USW00094994  43.1561  -90.6775  203.0 WI BOSCO...  USW00094994    WI   \n",
       "\n",
       "                                NAME  \n",
       "0     ADAMS 0.4 E                     \n",
       "1     NEKOOSA 8.0 SSE                 \n",
       "2     GRAND MARSH 1.0 W               \n",
       "3     GRAND MARSH 1.9 SSW             \n",
       "4     OXFORD 4.0 W                    \n",
       "...                              ...  \n",
       "1308  VOLK FLD ANG                    \n",
       "1309  SPARTA FT MCCOY                 \n",
       "1310  HAYWARD MUNI AP                 \n",
       "1311  MARSHFIELD MUNI AP              \n",
       "1312  BOSCOBEL AP                     \n",
       "\n",
       "[1313 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if row is 1313\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a20a7990-456e-4afd-97f4-f84dfa573476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1313"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insert_data = df.collect()\n",
    "len(insert_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46624fbb-d5a0-4cc5-8458-894605fb5faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert data into cassandra weather database stations table\n",
    "insert_cql = cass.prepare('''\n",
    "    insert into weather.stations (id, name)\n",
    "    values (?, ?)\n",
    "''')\n",
    "for i in insert_data:\n",
    "    cass.execute(insert_cql, (i['ID'], i['NAME']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d607ae8-cfea-4bc9-8455-19a33f6aebcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(count=1313)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if row of data in cassandra is 1313\n",
    "list(cass.execute('select count(*) from weather.stations;'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "878bb68c-b75a-498c-98d1-ffadd070fe17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MADISON DANE CO RGNL AP       '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q2\n",
    "cass.execute(\"select name from weather.stations where id = 'USW00014837'\").one()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42ffba42-1bc6-4782-81fc-51913c34abb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9014250178872933741"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q3\n",
    "tokenid = cass.execute(\"select token(id) from weather.stations where id = 'USC00470273'\").one()[0]\n",
    "tokenid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a2b52e3-7777-4e67-b79c-6f36b7425653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the output of command \"nodetool ring\"\n",
    "import subprocess\n",
    "result = subprocess.run(\"nodetool ring\", shell=True, stdout=subprocess.PIPE, text=True)\n",
    "result = result.stdout.strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e93fc37-997b-48df-b8cb-cb03b32f0e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the vnode number \n",
    "tokens = []\n",
    "for s in result:\n",
    "    try:\n",
    "        tokens.append(int(s.strip().split(' ')[-1]))\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "722dc522-ee0e-49d2-bec1-29b821604a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8273880671831934197"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q4\n",
    "# output the vnode number that is bigger than my token id and break\n",
    "ans = tokens[0]\n",
    "for t in tokens[1:]:\n",
    "    if t >= tokenid:\n",
    "        ans = t\n",
    "        break\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc53995-9fa5-4fdf-ae56-b799526be0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! unzip records.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1959e0e2-5ba2-4252-a660-a4559e299496",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/22 18:45:55 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# read parquetfile, do pivot to make a column into several columns (for tmin, tmax), and change the date format\n",
    "from pyspark.sql.functions import col, collect_list\n",
    "from pyspark.sql.functions import date_format, to_date\n",
    "df = spark.read.parquet('records.parquet')\n",
    "df = df.groupby('station','date').pivot(\"element\").agg({\"value\": \"first\"})\n",
    "df = df.withColumnRenamed('TMIN', 'tmin').withColumnRenamed('TMAX', 'tmax')\n",
    "df = df.withColumn(\"date\", date_format(to_date(col(\"date\"), \"yyyyMMdd\"), \"yyyy-MM-dd\"))\n",
    "records = df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2fa25d5-ef8a-479a-9369-58852e32991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python3 server.py (run the grpc sercer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f222eb77-b7c2-4f56-b061-ef89df188fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep sending data to the grpc server and let the server upload my data to cassandra\n",
    "import station_pb2, station_pb2_grpc\n",
    "import grpc\n",
    "\n",
    "port = 5440\n",
    "channel = grpc.insecure_channel(\"localhost:\" + str(port))\n",
    "stub = station_pb2_grpc.StationStub(channel)\n",
    "\n",
    "for i in records:\n",
    "    args = [i['station'], i['date'], i['tmin'], i['tmax']]\n",
    "    record_station = i['station']\n",
    "    record_date = i['date']\n",
    "    record_tmin = int(i['tmin'])\n",
    "    record_tmax = int(i['tmax'])\n",
    "    stub.RecordTemps(station_pb2.RecordTempsRequest(station = record_station, date = record_date, tmin = record_tmin, tmax = record_tmax ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f7d6c141-e876-46b5-a463-f36f8ba6cc59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cass.execute(\"select max(record.tmax) from weather.stations where id = 'USW00014837'\").one()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8ca46c8-2c4e-4be7-a90f-1d88c8e4959e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q5\n",
    "ans = stub.StationMax(station_pb2.StationMaxRequest(station = 'USW00014837'))\n",
    "ans.tmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d518abd3-6c24-46de-b624-6b04dc0100f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='stations', catalog=None, namespace=[], description=None, tableType='TEMPORARY', isTemporary=True)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q6\n",
    "mydata = (spark.read.format(\"org.apache.spark.sql.cassandra\")\n",
    ".option(\"spark.cassandra.connection.host\", \"p6-db-1,p6-db-2,p6-db-3\")\n",
    ".option(\"keyspace\", \"weather\")\n",
    ".option(\"table\", \"stations\")\n",
    ".load())\n",
    "mydata.createOrReplaceTempView('stations')\n",
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b0a84b93-d150-47eb-8f88-da2cda2edf95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'USW00014839': 89.6986301369863,\n",
       " 'USR0000WDDG': 102.06849315068493,\n",
       " 'USW00014837': 105.62739726027397,\n",
       " 'USW00014898': 102.93698630136986}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q7\n",
    "ans = spark.sql('select id, avg(record.tmax - record.tmin) from stations where record is not null group by id').collect()\n",
    "mydict = {}\n",
    "for i in ans:\n",
    "    mydict[i['id']] = i['avg((record.tmax - record.tmin))']\n",
    "mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "db08ccf5-b8c5-48d1-aaf3-df29812b682d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/sh: 1: docker: not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/22 19:00:22 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (java.nio.channels.NotYetConnectedException))\n"
     ]
    }
   ],
   "source": [
    "#! kill p6-db-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a5bce442-26d0-4e22-8cd9-96cfc1e983c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datacenter: datacenter1\n",
      "=======================\n",
      "Status=Up/Down\n",
      "|/ State=Normal/Leaving/Joining/Moving\n",
      "--  Address     Load        Tokens  Owns (effective)  Host ID                               Rack \n",
      "UN  172.30.0.4  149.19 KiB  16      100.0%            4f1af12d-da85-4433-bb76-6fd2454e33ac  rack1\n",
      "UN  172.30.0.2  149.56 KiB  16      100.0%            af67c5f5-8f79-4314-9cf7-35bacb0ffc0b  rack1\n",
      "DN  172.30.0.3  149.95 KiB  16      100.0%            95d4a654-cf32-462e-a95b-bb88684740ac  rack1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.30.0.3:9042, scheduling retry in 7.36 seconds: [Errno None] Tried connecting to [('172.30.0.3', 9042)]. Last error: timed out\n",
      "23/11/22 19:00:51 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (java.nio.channels.NotYetConnectedException))\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.30.0.3:9042, scheduling retry in 17.6 seconds: [Errno 113] Tried connecting to [('172.30.0.3', 9042)]. Last error: No route to host\n",
      "23/11/22 19:01:09 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.30.0.3:9042, scheduling retry in 31.04 seconds: [Errno 113] Tried connecting to [('172.30.0.3', 9042)]. Last error: No route to host\n",
      "23/11/22 19:01:44 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.30.0.3:9042, scheduling retry in 67.84 seconds: [Errno 113] Tried connecting to [('172.30.0.3', 9042)]. Last error: No route to host\n",
      "23/11/22 19:02:47 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.30.0.3:9042, scheduling retry in 131.84 seconds: [Errno 113] Tried connecting to [('172.30.0.3', 9042)]. Last error: No route to host\n",
      "23/11/22 19:03:41 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/22 19:04:38 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.30.0.3:9042, scheduling retry in 261.12 seconds: [Errno 113] Tried connecting to [('172.30.0.3', 9042)]. Last error: No route to host\n",
      "23/11/22 19:05:38 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/22 19:06:38 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n"
     ]
    }
   ],
   "source": [
    "#q8\n",
    "! nodetool status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "54e5008d-9873-451e-837d-4677924b23d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "error: \"need 3 replicas, but only have 2\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/22 19:12:24 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/22 19:13:19 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/22 19:14:21 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/22 19:15:25 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n"
     ]
    }
   ],
   "source": [
    "#q9\n",
    "stub.StationMax(station_pb2.StationMaxRequest(station = 'USW00014837'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "29f72a16-8bf2-4890-9a92-3ecfca09cd82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/22 19:16:20 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/22 19:17:22 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/22 19:18:25 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.30.0.3:9042, scheduling retry in 600.0 seconds: [Errno 113] Tried connecting to [('172.30.0.3', 9042)]. Last error: No route to host\n",
      "23/11/22 19:19:27 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/22 19:20:30 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/22 19:21:33 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/22 19:22:36 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/22 19:23:39 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/22 19:24:42 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/22 19:25:45 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/22 19:26:48 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/22 19:27:51 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/22 19:28:55 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.30.0.3:9042, scheduling retry in 576.0 seconds: [Errno 113] Tried connecting to [('172.30.0.3', 9042)]. Last error: No route to host\n",
      "23/11/22 19:29:53 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/22 19:30:51 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/22 19:31:47 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/22 19:32:50 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/22 19:33:49 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/22 19:34:44 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/22 19:35:44 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/22 19:36:47 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/22 19:37:43 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/22 19:38:35 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.30.0.3:9042, scheduling retry in 546.0 seconds: [Errno 113] Tried connecting to [('172.30.0.3', 9042)]. Last error: No route to host\n",
      "23/11/22 19:39:35 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/22 19:40:38 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/22 19:41:37 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/22 19:42:32 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/22 19:43:35 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/22 19:44:30 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/22 19:45:31 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/22 19:46:34 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "23/11/22 19:47:37 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n",
      "WARNING:cassandra.pool:Error attempting to reconnect to 172.30.0.3:9042, scheduling retry in 540.0 seconds: [Errno 113] Tried connecting to [('172.30.0.3', 9042)]. Last error: No route to host\n",
      "23/11/22 19:48:40 WARN ChannelPool: [s0|p6-db-2/172.30.0.3:9042]  Error while opening new channel (ConnectionInitException: [s0|connecting...] Protocol initialization request, step 1 (STARTUP {CQL_VERSION=3.0.0, DRIVER_NAME=DataStax Java driver for Apache Cassandra(R), DRIVER_VERSION=4.13.0, CLIENT_ID=7ce28593-5cf9-4518-9942-d56e249602fb, APPLICATION_NAME=Spark-Cassandra-Connector-local-1700674687170}): failed to send request (com.datastax.oss.driver.shaded.netty.channel.StacklessClosedChannelException))\n"
     ]
    }
   ],
   "source": [
    "#q10\n",
    "stub.RecordTemps(station_pb2.RecordTempsRequest(station = 'USW00014837', date = '2022-11-22', tmin = 1, tmax = 90 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85aed8f0-4bc5-427f-9390-fe62296b8a90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
